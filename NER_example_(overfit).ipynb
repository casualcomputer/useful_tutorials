{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtQkT8n0IejtaMqtRiVfBW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casualcomputer/useful_tutorials/blob/main/NER_example_(overfit).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terminologies:**\n",
        "\n",
        "* geo = Geographical Entity\n",
        "\n",
        "* org = Organization\n",
        "\n",
        "* per = Person\n",
        "\n",
        "* gpe = Geopolitical Entity\n",
        "\n",
        "* tim = Time indicator\n",
        "\n",
        "* art = Artifact\n",
        "\n",
        "* eve = Event\n",
        "\n",
        "* nat = Natural Phenomenon"
      ],
      "metadata": {
        "id": "tRIfEQGdj2j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommended reference: https://ner.pythonhumanities.com/03_01_create_ner_training_set.html#"
      ],
      "metadata": {
        "id": "-Iz1J56JlP3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data"
      ],
      "metadata": {
        "id": "vsWQS5fUrb3h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load config file (basse model: https://spacy.io/usage/training)\n",
        "\n",
        "%%writefile data/base_config.cfg\n",
        "# This is an auto-generated partial config. To use it with 'spacy train'\n",
        "# you can run spacy init fill-config to auto-fill all default settings:\n",
        "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
        "\n",
        "# ! change train, and dev\n",
        "\n",
        "[paths]\n",
        "train = data/train.spacy\n",
        "dev =  data/valid.spacy\n",
        "vectors = null\n",
        "\n",
        "[system]\n",
        "gpu_allocator = null\n",
        "\n",
        "[nlp]\n",
        "lang = \"en\"\n",
        "pipeline = [\"tok2vec\",\"ner\"]\n",
        "batch_size = 1000\n",
        "\n",
        "[components]\n",
        "\n",
        "[components.tok2vec]\n",
        "factory = \"tok2vec\"\n",
        "\n",
        "[components.tok2vec.model]\n",
        "@architectures = \"spacy.Tok2Vec.v2\"\n",
        "\n",
        "[components.tok2vec.model.embed]\n",
        "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
        "width = ${components.tok2vec.model.encode.width}\n",
        "attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
        "rows = [5000, 1000, 2500, 2500]\n",
        "include_static_vectors = false\n",
        "\n",
        "[components.tok2vec.model.encode]\n",
        "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
        "width = 96\n",
        "depth = 4\n",
        "window_size = 1\n",
        "maxout_pieces = 3\n",
        "\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "\n",
        "[components.ner.model]\n",
        "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
        "state_type = \"ner\"\n",
        "extra_state_tokens = false\n",
        "hidden_width = 64\n",
        "maxout_pieces = 2\n",
        "use_upper = true\n",
        "nO = null\n",
        "\n",
        "[components.ner.model.tok2vec]\n",
        "@architectures = \"spacy.Tok2VecListener.v1\"\n",
        "width = ${components.tok2vec.model.encode.width}\n",
        "\n",
        "[corpora]\n",
        "\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "max_length = 0\n",
        "\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "max_length = 0\n",
        "\n",
        "[training]\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_words.v1\"\n",
        "discard_oversize = false\n",
        "tolerance = 0.2\n",
        "\n",
        "[training.batcher.size]\n",
        "@schedules = \"compounding.v1\"\n",
        "start = 100\n",
        "stop = 1000\n",
        "compound = 1.001\n",
        "\n",
        "[initialize]\n",
        "vectors = ${paths.vectors}"
      ],
      "metadata": {
        "id": "s65HVNNRriog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af795542-721a-4853-a169-7e455909d451"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data/base_config.cfg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Treblinka is a small village in Poland. Wikipedia notes that Treblinka is not large.\"\n",
        "corpus = []\n",
        "\n",
        "doc = nlp(text)\n",
        "for sent in doc.sents:\n",
        "    corpus.append(sent.text)\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "patterns = [\n",
        "                {\"label\": \"GPE\", \"pattern\": \"Treblinka\"}\n",
        "            ]\n",
        "\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "TRAIN_DATA = []\n",
        "for sentence in corpus:\n",
        "    doc = nlp(sentence)\n",
        "    entities = []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
        "    TRAIN_DATA.append([sentence, {\"entities\": entities}])\n",
        "\n",
        "print (TRAIN_DATA)\n",
        "\n",
        "# How to Convert the Training Data to spaCy Binary Files¶ (conversion function)\n",
        "import srsly\n",
        "import typer\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "def convert(lang: str, TRAIN_DATA, output_path: Path):\n",
        "    nlp = spacy.blank(lang)\n",
        "    db = DocBin()\n",
        "    for text, annot in TRAIN_DATA:\n",
        "        doc = nlp.make_doc(text)\n",
        "        ents = []\n",
        "        for start, end, label in annot[\"entities\"]:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            if span is None:\n",
        "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
        "                warnings.warn(msg)\n",
        "            else:\n",
        "                ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "    db.to_disk(output_path)\n",
        "\n",
        "#execute the functions to create training datasets\n",
        "convert(\"en\", TRAIN_DATA, \"data/train.spacy\")\n",
        "convert(\"en\", TRAIN_DATA, \"data/valid.spacy\") #! red flag: training data shouldn't be the same as testing data"
      ],
      "metadata": {
        "id": "dXIzFV-qs8kH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba314a9c-3102-4cac-dda3-f280d6025ea2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Treblinka is a small village in Poland.', {'entities': [[0, 9, 'GPE']]}], ['Wikipedia notes that Treblinka is not large.', {'entities': [[21, 30, 'GPE']]}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kb06cyEnjmSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "becaf5b2-fcf8-4666-cb29-556e7640dd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-05 10:27:48.343319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "data/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config data/base_config.cfg data/config.cfg #input basee_config, output config as model file data/config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train data/config.cfg --output ./models/output"
      ],
      "metadata": {
        "id": "1fxhc1Tqj1_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c286a4e6-2d93-4ae6-b5ff-3b68bc97b4c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-05 10:27:59.292559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: models/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: models/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-07-05 10:28:02,428] [INFO] Set up nlp object from config\n",
            "[2023-07-05 10:28:02,449] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2023-07-05 10:28:02,454] [INFO] Created vocabulary\n",
            "[2023-07-05 10:28:02,454] [INFO] Finished initializing nlp object\n",
            "[2023-07-05 10:28:02,566] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00      7.83   57.14   40.00  100.00    0.57\n",
            "200     200          0.15     95.20  100.00  100.00  100.00    1.00\n",
            "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models/output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to ChatGPT:"
      ],
      "metadata": {
        "id": "vbd93zu2zp06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PROMPT: how do i read the following spacy outputs: [INSERT THE TABLE ABOVE]?\n",
        "\n",
        "# \"The output you provided seems to be the training pipeline and performance metrics of a spaCy model. Here's how you can interpret the information:\n",
        "\n",
        "# The training pipeline consists of two components: 'tok2vec' and 'ner'. 'tok2vec' is responsible for tokenization and vectorization, while 'ner' refers to the named entity recognition component.\n",
        "# The initial learning rate for the training process is set to 0.001.\n",
        "# The table displays the training progress over several epochs.\n",
        "# The columns in the table represent the following metrics:\n",
        "# #: The epoch number or iteration count.\n",
        "# LOSS TOK2VEC: The loss value associated with the 'tok2vec' component. A lower loss indicates better performance.\n",
        "# LOSS NER: The loss value associated with the 'ner' component. Again, a lower loss is desirable.\n",
        "# ENTS_F: The F1 score for named entity recognition. It is a measure of the model's precision and recall.\n",
        "# ENTS_P: The precision score for named entity recognition.\n",
        "# ENTS_R: The recall score for named entity recognition.\n",
        "# SCORE: An overall score combining multiple metrics to evaluate the model's performance.\n",
        "# In the provided output, the training starts with relatively high losses for both 'tok2vec' and 'ner'. However, as the training progresses, the losses decrease to 0.00, indicating that the model is learning effectively. The named entity recognition metrics (ENTS_F, ENTS_P, and ENTS_R) show perfect scores of 100.00, indicating that the model is achieving accurate entity recognition.\n",
        "\n",
        "# Finally, it mentions that the trained pipeline has been saved to the output directory 'models/output/model-last'.\"\n",
        "\n",
        "\n",
        "#PS. on a serious note, to understand the config file, go to https://spacy.io/api/architectures"
      ],
      "metadata": {
        "id": "rBYwGxfKz6h1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Clearly, we overfitted. Why?\n",
        "*   Great, we trained a terrible model? See codes below.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F4lwY6CL0P8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perfect fit on the exact entity\n",
        "trained_nlp = spacy.load(\"models/output/model-best\")\n",
        "text = \"The village of Treblinka is located in Poland.\"\n",
        "doc = trained_nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yibwnQO81Ex_",
        "outputId": "31c72d9c-1b80-4dcb-e0fd-f5a33baf6166"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treblinka GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yet... with a small variation... does the NER still work?\n",
        "\n",
        "text = \"Mark, from New York, said that he wants to go to Treblinkaaaazazaza to speak to the locals.\"\n",
        "doc = trained_nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)\n",
        "if len(doc.ents) == 0:\n",
        "    print (\"No entities found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uFTE4jV1b0p",
        "outputId": "48ecfe46-7691-4be3-84f3-da0f1011279c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treblinkaaaazazaza GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# too few training examples. we were just lucky?"
      ],
      "metadata": {
        "id": "ihUjUT_G1yYs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation can be a pain. Things to think about:\n",
        "\n",
        "1.   What are the best ways to create labelled data?\n",
        "2.   How do we use generative AI to create labels efficiently?\n",
        "\n",
        "Cool stuff:\n",
        "1.   How to load word vectors into spacy? https://ner.pythonhumanities.com/03_06_loading_custom_word_vectors.html\n",
        "\n",
        "Red flag:\n",
        "1.   Looks like spacy depends on tensorflow... ahhhh"
      ],
      "metadata": {
        "id": "fzEk6FdN2VlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 freeze > requirements.txt  # Python3"
      ],
      "metadata": {
        "id": "9zD7icIf36jm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile requirements.txt\n",
        "# absl-py==1.4.0\n",
        "# aiohttp==3.8.4\n",
        "# aiosignal==1.3.1\n",
        "# alabaster==0.7.13\n",
        "# albumentations==1.2.1\n",
        "# altair==4.2.2\n",
        "# anyio==3.7.0\n",
        "# appdirs==1.4.4\n",
        "# argon2-cffi==21.3.0\n",
        "# argon2-cffi-bindings==21.2.0\n",
        "# array-record==0.4.0\n",
        "# arviz==0.15.1\n",
        "# astropy==5.2.2\n",
        "# astunparse==1.6.3\n",
        "# async-timeout==4.0.2\n",
        "# attrs==23.1.0\n",
        "# audioread==3.0.0\n",
        "# autograd==1.6.1\n",
        "# Babel==2.12.1\n",
        "# backcall==0.2.0\n",
        "# beautifulsoup4==4.11.2\n",
        "# bleach==6.0.0\n",
        "# blis==0.7.9\n",
        "# blosc2==2.0.0\n",
        "# bokeh==2.4.3\n",
        "# branca==0.6.0\n",
        "# build==0.10.0\n",
        "# CacheControl==0.13.1\n",
        "# cached-property==1.5.2\n",
        "# cachetools==5.3.1\n",
        "# catalogue==2.0.8\n",
        "# certifi==2023.5.7\n",
        "# cffi==1.15.1\n",
        "# chardet==4.0.0\n",
        "# charset-normalizer==2.0.12\n",
        "# chex==0.1.7\n",
        "# click==8.1.3\n",
        "# click-plugins==1.1.1\n",
        "# cligj==0.7.2\n",
        "# cloudpickle==2.2.1\n",
        "# cmake==3.25.2\n",
        "# cmdstanpy==1.1.0\n",
        "# colorcet==3.0.1\n",
        "# colorlover==0.3.0\n",
        "# community==1.0.0b1\n",
        "# confection==0.0.4\n",
        "# cons==0.4.6\n",
        "# contextlib2==0.6.0.post1\n",
        "# contourpy==1.1.0\n",
        "# convertdate==2.4.0\n",
        "# cufflinks==0.17.3\n",
        "# cvxopt==1.3.1\n",
        "# cvxpy==1.3.1\n",
        "# cycler==0.11.0\n",
        "# cymem==2.0.7\n",
        "# Cython==0.29.35\n",
        "# dask==2022.12.1\n",
        "# datascience==0.17.6\n",
        "# db-dtypes==1.1.1\n",
        "# dbus-python==1.2.16\n",
        "# debugpy==1.6.6\n",
        "# decorator==4.4.2\n",
        "# defusedxml==0.7.1\n",
        "# distributed==2022.12.1\n",
        "# dlib==19.24.2\n",
        "# dm-tree==0.1.8\n",
        "# docutils==0.16\n",
        "# dopamine-rl==4.0.6\n",
        "# duckdb==0.8.1\n",
        "# earthengine-api==0.1.357\n",
        "# easydict==1.10\n",
        "# ecos==2.0.12\n",
        "# editdistance==0.6.2\n",
        "# en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n",
        "# entrypoints==0.4\n",
        "# ephem==4.1.4\n",
        "# et-xmlfile==1.1.0\n",
        "# etils==1.3.0\n",
        "# etuples==0.3.9\n",
        "# exceptiongroup==1.1.1\n",
        "# fastai==2.7.12\n",
        "# fastcore==1.5.29\n",
        "# fastdownload==0.0.7\n",
        "# fastjsonschema==2.17.1\n",
        "# fastprogress==1.0.3\n",
        "# fastrlock==0.8.1\n",
        "# filelock==3.12.2\n",
        "# Fiona==1.9.4.post1\n",
        "# firebase-admin==5.3.0\n",
        "# Flask==2.2.5\n",
        "# flatbuffers==23.5.26\n",
        "# flax==0.6.11\n",
        "# folium==0.14.0\n",
        "# fonttools==4.40.0\n",
        "# frozendict==2.3.8\n",
        "# frozenlist==1.3.3\n",
        "# fsspec==2023.6.0\n",
        "# future==0.18.3\n",
        "# gast==0.4.0\n",
        "# gcsfs==2023.6.0\n",
        "# GDAL==3.3.2\n",
        "# gdown==4.6.6\n",
        "# gensim==4.3.1\n",
        "# geographiclib==2.0\n",
        "# geopandas==0.13.2\n",
        "# geopy==2.3.0\n",
        "# gin-config==0.5.0\n",
        "# glob2==0.7\n",
        "# google==2.0.3\n",
        "# google-api-core==2.11.1\n",
        "# google-api-python-client==2.84.0\n",
        "# google-auth==2.17.3\n",
        "# google-auth-httplib2==0.1.0\n",
        "# google-auth-oauthlib==1.0.0\n",
        "# google-cloud-bigquery==3.10.0\n",
        "# google-cloud-bigquery-connection==1.12.0\n",
        "# google-cloud-bigquery-storage==2.20.0\n",
        "# google-cloud-core==2.3.2\n",
        "# google-cloud-datastore==2.15.2\n",
        "# google-cloud-firestore==2.11.1\n",
        "# google-cloud-functions==1.13.0\n",
        "# google-cloud-language==2.9.1\n",
        "# google-cloud-storage==2.8.0\n",
        "# google-cloud-translate==3.11.1\n",
        "# google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=e1dbf1675b82118c05ec840f6e658f6a5329ad5203c0f6051f010bb87ae5147f\n",
        "# google-crc32c==1.5.0\n",
        "# google-pasta==0.2.0\n",
        "# google-resumable-media==2.5.0\n",
        "# googleapis-common-protos==1.59.1\n",
        "# googledrivedownloader==0.4\n",
        "# graphviz==0.20.1\n",
        "# greenlet==2.0.2\n",
        "# grpc-google-iam-v1==0.12.6\n",
        "# grpcio==1.56.0\n",
        "# grpcio-status==1.48.2\n",
        "# gspread==3.4.2\n",
        "# gspread-dataframe==3.0.8\n",
        "# gym==0.25.2\n",
        "# gym-notices==0.0.8\n",
        "# h5netcdf==1.2.0\n",
        "# h5py==3.8.0\n",
        "# holidays==0.27.1\n",
        "# holoviews==1.15.4\n",
        "# html5lib==1.1\n",
        "# httpimport==1.3.0\n",
        "# httplib2==0.21.0\n",
        "# humanize==4.6.0\n",
        "# hyperopt==0.2.7\n",
        "# idna==3.4\n",
        "# imageio==2.25.1\n",
        "# imageio-ffmpeg==0.4.8\n",
        "# imagesize==1.4.1\n",
        "# imbalanced-learn==0.10.1\n",
        "# imgaug==0.4.0\n",
        "# importlib-resources==5.12.0\n",
        "# imutils==0.5.4\n",
        "# inflect==6.0.4\n",
        "# iniconfig==2.0.0\n",
        "# intel-openmp==2023.1.0\n",
        "# ipykernel==5.5.6\n",
        "# ipython==7.34.0\n",
        "# ipython-genutils==0.2.0\n",
        "# ipython-sql==0.4.1\n",
        "# ipywidgets==7.7.1\n",
        "# itsdangerous==2.1.2\n",
        "# jax==0.4.10\n",
        "# jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.10+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=fe53205ef12727c80ed5ac2d4506d6732c0c3db69ede4565a7d4df98e609af84\n",
        "# jieba==0.42.1\n",
        "# Jinja2==3.1.2\n",
        "# joblib==1.2.0\n",
        "# jsonpickle==3.0.1\n",
        "# jsonschema==4.3.3\n",
        "# jupyter-client==6.1.12\n",
        "# jupyter-console==6.1.0\n",
        "# jupyter-server==1.24.0\n",
        "# jupyter_core==5.3.1\n",
        "# jupyterlab-pygments==0.2.2\n",
        "# jupyterlab-widgets==3.0.7\n",
        "# kaggle==1.5.13\n",
        "# keras==2.12.0\n",
        "# kiwisolver==1.4.4\n",
        "# langcodes==3.3.0\n",
        "# lazy_loader==0.2\n",
        "# libclang==16.0.0\n",
        "# librosa==0.10.0.post2\n",
        "# lightgbm==3.3.5\n",
        "# lit==16.0.6\n",
        "# llvmlite==0.39.1\n",
        "# locket==1.0.0\n",
        "# logical-unification==0.4.6\n",
        "# LunarCalendar==0.0.9\n",
        "# lxml==4.9.2\n",
        "# Markdown==3.4.3\n",
        "# markdown-it-py==3.0.0\n",
        "# MarkupSafe==2.1.3\n",
        "# matplotlib==3.7.1\n",
        "# matplotlib-inline==0.1.6\n",
        "# matplotlib-venn==0.11.9\n",
        "# mdurl==0.1.2\n",
        "# miniKanren==1.0.3\n",
        "# missingno==0.5.2\n",
        "# mistune==0.8.4\n",
        "# mizani==0.8.1\n",
        "# mkl==2019.0\n",
        "# ml-dtypes==0.2.0\n",
        "# mlxtend==0.14.0\n",
        "# more-itertools==9.1.0\n",
        "# moviepy==1.0.3\n",
        "# mpmath==1.3.0\n",
        "# msgpack==1.0.5\n",
        "# multidict==6.0.4\n",
        "# multipledispatch==0.6.0\n",
        "# multitasking==0.0.11\n",
        "# murmurhash==1.0.9\n",
        "# music21==8.1.0\n",
        "# natsort==8.3.1\n",
        "# nbclient==0.8.0\n",
        "# nbconvert==6.5.4\n",
        "# nbformat==5.9.0\n",
        "# nest-asyncio==1.5.6\n",
        "# networkx==3.1\n",
        "# nibabel==3.0.2\n",
        "# nltk==3.8.1\n",
        "# notebook==6.4.8\n",
        "# numba==0.56.4\n",
        "# numexpr==2.8.4\n",
        "# numpy==1.22.4\n",
        "# oauth2client==4.1.3\n",
        "# oauthlib==3.2.2\n",
        "# opencv-contrib-python==4.7.0.72\n",
        "# opencv-python==4.7.0.72\n",
        "# opencv-python-headless==4.7.0.72\n",
        "# openpyxl==3.0.10\n",
        "# opt-einsum==3.3.0\n",
        "# optax==0.1.5\n",
        "# orbax-checkpoint==0.2.6\n",
        "# osqp==0.6.2.post8\n",
        "# packaging==23.1\n",
        "# palettable==3.3.3\n",
        "# pandas==1.5.3\n",
        "# pandas-datareader==0.10.0\n",
        "# pandas-gbq==0.17.9\n",
        "# pandocfilters==1.5.0\n",
        "# panel==0.14.4\n",
        "# param==1.13.0\n",
        "# parso==0.8.3\n",
        "# partd==1.4.0\n",
        "# pathlib==1.0.1\n",
        "# pathy==0.10.2\n",
        "# patsy==0.5.3\n",
        "# pexpect==4.8.0\n",
        "# pickleshare==0.7.5\n",
        "# Pillow==8.4.0\n",
        "# pip-tools==6.13.0\n",
        "# platformdirs==3.7.0\n",
        "# plotly==5.13.1\n",
        "# plotnine==0.10.1\n",
        "# pluggy==1.2.0\n",
        "# polars==0.17.3\n",
        "# pooch==1.6.0\n",
        "# portpicker==1.5.2\n",
        "# prefetch-generator==1.0.3\n",
        "# preshed==3.0.8\n",
        "# prettytable==0.7.2\n",
        "# proglog==0.1.10\n",
        "# progressbar2==4.2.0\n",
        "# prometheus-client==0.17.0\n",
        "# promise==2.3\n",
        "# prompt-toolkit==3.0.38\n",
        "# prophet==1.1.4\n",
        "# proto-plus==1.22.3\n",
        "# protobuf==3.20.3\n",
        "# psutil==5.9.5\n",
        "# psycopg2==2.9.6\n",
        "# ptyprocess==0.7.0\n",
        "# py-cpuinfo==9.0.0\n",
        "# py4j==0.10.9.7\n",
        "# pyarrow==9.0.0\n",
        "# pyasn1==0.5.0\n",
        "# pyasn1-modules==0.3.0\n",
        "# pycocotools==2.0.6\n",
        "# pycparser==2.21\n",
        "# pyct==0.5.0\n",
        "# pydantic==1.10.9\n",
        "# pydata-google-auth==1.8.0\n",
        "# pydot==1.4.2\n",
        "# pydot-ng==2.0.0\n",
        "# pydotplus==2.0.2\n",
        "# PyDrive==1.3.1\n",
        "# pyerfa==2.0.0.3\n",
        "# pygame==2.4.0\n",
        "# Pygments==2.14.0\n",
        "# PyGObject==3.36.0\n",
        "# pymc==5.1.2\n",
        "# PyMeeus==0.5.12\n",
        "# pymystem3==0.2.0\n",
        "# PyOpenGL==3.1.7\n",
        "# pyparsing==3.1.0\n",
        "# pyproj==3.6.0\n",
        "# pyproject_hooks==1.0.0\n",
        "# pyrsistent==0.19.3\n",
        "# PySocks==1.7.1\n",
        "# pytensor==2.10.1\n",
        "# pytest==7.2.2\n",
        "# python-apt==0.0.0\n",
        "# python-dateutil==2.8.2\n",
        "# python-louvain==0.16\n",
        "# python-slugify==8.0.1\n",
        "# python-utils==3.7.0\n",
        "# pytz==2022.7.1\n",
        "# pyviz-comms==2.3.2\n",
        "# PyWavelets==1.4.1\n",
        "# PyYAML==6.0\n",
        "# pyzmq==23.2.1\n",
        "# qdldl==0.1.7\n",
        "# qudida==0.0.4\n",
        "# regex==2022.10.31\n",
        "# requests==2.27.1\n",
        "# requests-oauthlib==1.3.1\n",
        "# requests-unixsocket==0.2.0\n",
        "# requirements-parser==0.5.0\n",
        "# rich==13.4.2\n",
        "# rpy2==3.5.5\n",
        "# rsa==4.9\n",
        "# scikit-image==0.19.3\n",
        "# scikit-learn==1.2.2\n",
        "# scipy==1.10.1\n",
        "# scs==3.2.3\n",
        "# seaborn==0.12.2\n",
        "# Send2Trash==1.8.2\n",
        "# shapely==2.0.1\n",
        "# six==1.16.0\n",
        "# sklearn-pandas==2.2.0\n",
        "# smart-open==6.3.0\n",
        "# sniffio==1.3.0\n",
        "# snowballstemmer==2.2.0\n",
        "# sortedcontainers==2.4.0\n",
        "# soundfile==0.12.1\n",
        "# soupsieve==2.4.1\n",
        "# soxr==0.3.5\n",
        "# spacy==3.5.3\n",
        "# spacy-legacy==3.0.12\n",
        "# spacy-loggers==1.0.4\n",
        "# Sphinx==3.5.4\n",
        "# sphinxcontrib-applehelp==1.0.4\n",
        "# sphinxcontrib-devhelp==1.0.2\n",
        "# sphinxcontrib-htmlhelp==2.0.1\n",
        "# sphinxcontrib-jsmath==1.0.1\n",
        "# sphinxcontrib-qthelp==1.0.3\n",
        "# sphinxcontrib-serializinghtml==1.1.5\n",
        "# SQLAlchemy==2.0.16\n",
        "# sqlparse==0.4.4\n",
        "# srsly==2.4.6\n",
        "# statsmodels==0.13.5\n",
        "# sympy==1.11.1\n",
        "# tables==3.8.0\n",
        "# tabulate==0.8.10\n",
        "# tblib==2.0.0\n",
        "# tenacity==8.2.2\n",
        "# tensorboard==2.12.3\n",
        "# tensorboard-data-server==0.7.1\n",
        "# tensorflow==2.12.0\n",
        "# tensorflow-datasets==4.9.2\n",
        "# tensorflow-estimator==2.12.0\n",
        "# tensorflow-gcs-config==2.12.0\n",
        "# tensorflow-hub==0.13.0\n",
        "# tensorflow-io-gcs-filesystem==0.32.0\n",
        "# tensorflow-metadata==1.13.1\n",
        "# tensorflow-probability==0.20.1\n",
        "# tensorstore==0.1.38\n",
        "# termcolor==2.3.0\n",
        "# terminado==0.17.1\n",
        "# text-unidecode==1.3\n",
        "# textblob==0.17.1\n",
        "# tf-slim==1.1.0\n",
        "# thinc==8.1.10\n",
        "# threadpoolctl==3.1.0\n",
        "# tifffile==2023.4.12\n",
        "# tinycss2==1.2.1\n",
        "# toml==0.10.2\n",
        "# tomli==2.0.1\n",
        "# toolz==0.12.0\n",
        "# torch @ https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a7a49d459bf4862f64f7bc1a68beccf8881c2fa9f3e0569608e16ba6f85ebf7b\n",
        "# torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=26692645ea061a005c57ec581a2d0425210ac6ba9f923edf11cc9b0ef3a111e9\n",
        "# torchdata==0.6.1\n",
        "# torchsummary==1.5.1\n",
        "# torchtext==0.15.2\n",
        "# torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=19ca4ab5d6179bbe53cff79df1a855ee6533c2861ddc7389f68349d8b9f8302a\n",
        "# tornado==6.3.1\n",
        "# tqdm==4.65.0\n",
        "# traitlets==5.7.1\n",
        "# triton==2.0.0\n",
        "# tweepy==4.13.0\n",
        "# typer==0.7.0\n",
        "# types-setuptools==68.0.0.0\n",
        "# typing_extensions==4.6.3\n",
        "# tzlocal==5.0.1\n",
        "# uritemplate==4.1.1\n",
        "# urllib3==1.26.16\n",
        "# vega-datasets==0.9.0\n",
        "# wasabi==1.1.2\n",
        "# wcwidth==0.2.6\n",
        "# webcolors==1.13\n",
        "# webencodings==0.5.1\n",
        "# websocket-client==1.6.0\n",
        "# Werkzeug==2.3.6\n",
        "# widgetsnbextension==3.6.4\n",
        "# wordcloud==1.8.2.2\n",
        "# wrapt==1.14.1\n",
        "# xarray==2022.12.0\n",
        "# xarray-einstats==0.5.1\n",
        "# xgboost==1.7.6\n",
        "# xlrd==2.0.1\n",
        "# yarl==1.9.2\n",
        "# yellowbrick==1.5\n",
        "# yfinance==0.2.21\n",
        "# zict==3.0.0\n",
        "# zipp==3.15.0"
      ],
      "metadata": {
        "id": "8rwlnwSb4BWj"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}